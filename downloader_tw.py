# -*- coding: utf-8 -*-
import os, io, time, random, sqlite3, requests, re
import pandas as pd
import yfinance as yf
from io import StringIO
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ========== 1. ç’°å¢ƒåˆ¤æ–·èˆ‡åƒæ•¸è¨­å®š ==========
MARKET_CODE = "tw-share"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "tw_stock_warehouse.db")

# ğŸ’¡ è‡ªå‹•åˆ¤æ–·ç’°å¢ƒï¼šGitHub Actions åŸ·è¡Œæ™‚æ­¤è®Šæ•¸ç‚º true
IS_GITHUB_ACTIONS = os.getenv('GITHUB_ACTIONS') == 'true'

# âœ… å¿«å–è¨­å®š
CACHE_DIR = os.path.join(BASE_DIR, "cache_tw")
DATA_EXPIRY_SECONDS = 86400  # æœ¬æ©Ÿå¿«å–æ•ˆæœŸï¼š24å°æ™‚

if not IS_GITHUB_ACTIONS and not os.path.exists(CACHE_DIR):
    os.makedirs(CACHE_DIR, exist_ok=True)

# âœ… æ•ˆèƒ½è¨­å®šï¼šå°è‚¡å°é€£ç·šè¼ƒæ•æ„Ÿï¼Œä¸å®œéé«˜
MAX_WORKERS = 3 if IS_GITHUB_ACTIONS else 4 

def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}")

# ========== 2. æ ¸å¿ƒè¼”åŠ©å‡½å¼ ==========

def insert_or_replace(table, conn, keys, data_iter):
    """é˜²æ­¢é‡è¤‡å¯«å…¥çš„æ ¸å¿ƒ SQL é‚è¼¯"""
    sql = f"INSERT OR REPLACE INTO {table.name} ({', '.join(keys)}) VALUES ({', '.join(['?']*len(keys))})"
    conn.executemany(sql, data_iter)

def init_db():
    """åˆå§‹åŒ–è³‡æ–™åº«çµæ§‹"""
    conn = sqlite3.connect(DB_PATH)
    try:
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_prices (
                            date TEXT, symbol TEXT, open REAL, high REAL, 
                            low REAL, close REAL, volume INTEGER,
                            PRIMARY KEY (date, symbol))''')
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_info (
                            symbol TEXT PRIMARY KEY, name TEXT, sector TEXT, updated_at TEXT)''')
        conn.commit()
    finally:
        conn.close()

def get_tw_stock_list():
    """å¾è­‰äº¤æ‰€ç²å–å…¨å¸‚å ´æ¸…å–®ä¸¦åŒæ­¥å¯«å…¥ stock_info"""
    url_configs = [
        {'name': 'listed', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=1&issuetype=1&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'otc', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=2&issuetype=4&Page=1&chklike=Y', 'suffix': '.TWO'},
        {'name': 'etf', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=1&issuetype=I&industry_code=&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'rotc', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=E&issuetype=R&industry_code=&Page=1&chklike=Y', 'suffix': '.TWO'},
    ]
    
    log(f"ğŸ“¡ ç²å–å°è‚¡æ¸…å–®... (ç’°å¢ƒ: {'GitHub' if IS_GITHUB_ACTIONS else 'Local'})")
    conn = sqlite3.connect(DB_PATH)
    stock_list = []
    
    for cfg in url_configs:
        try:
            resp = requests.get(cfg['url'], timeout=15)
            # ä½¿ç”¨ StringIO åŒ…è£¹ resp.text é¿å… Future Warning
            df_list = pd.read_html(StringIO(resp.text), header=0)
            if not df_list: continue
            df = df_list[0]
            
            for _, row in df.iterrows():
                code = str(row['æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿ']).strip()
                name = str(row['æœ‰åƒ¹è­‰åˆ¸åç¨±']).strip()
                sector = str(row.get('ç”¢æ¥­åˆ¥', 'Unknown')).strip()
                
                # éæ¿¾éè‚¡ç¢¼ä¹‹è¡¨é ­å­—ä¸²
                if code.isalnum() and len(code) >= 4:
                    symbol = f"{code}{cfg['suffix']}"
                    conn.execute("INSERT OR REPLACE INTO stock_info (symbol, name, sector, updated_at) VALUES (?, ?, ?, ?)",
                                 (symbol, name, sector, datetime.now().strftime("%Y-%m-%d")))
                    stock_list.append((symbol, name))
        except Exception as e:
            log(f"âš ï¸ ç²å– {cfg['name']} å¸‚å ´å¤±æ•—: {e}")
            
    conn.commit()
    conn.close()
    
    unique_items = list(set(stock_list))
    log(f"âœ… å°è‚¡æ¸…å–®åŒæ­¥å®Œæˆï¼Œæ¨™çš„: {len(unique_items)} æª”")
    return unique_items

# ========== 3. æ ¸å¿ƒä¸‹è¼‰/å¿«å–åˆ†æµé‚è¼¯ ==========

def download_one(args):
    symbol, name, mode = args
    csv_path = os.path.abspath(os.path.join(CACHE_DIR, f"{symbol}.csv"))
    start_date = "2020-01-01" if mode == 'hot' else "1993-01-04"
    
    # --- âš¡ é–ƒé›»å¿«å–åˆ†æµ ---
    if not IS_GITHUB_ACTIONS and os.path.exists(csv_path):
        file_age = time.time() - os.path.getmtime(csv_path)
        if file_age < DATA_EXPIRY_SECONDS:
            return {"symbol": symbol, "status": "cache"}

    try:
        # äºç§’ç´šéš¨æ©Ÿç­‰å¾…ï¼Œå°è‚¡é »ç‡é™åˆ¶è¼ƒåš´
        time.sleep(random.uniform(0.5, 1.2))
        
        tk = yf.Ticker(symbol)
        # å°è‚¡å»ºè­° auto_adjust=True ä»¥è™•ç†é™¤æ¬Šæ¯
        hist = tk.history(start=start_date, timeout=25, auto_adjust=True)
        
        if hist is None or hist.empty:
            return {"symbol": symbol, "status": "empty"}
            
        hist.reset_index(inplace=True)
        hist.columns = [c.lower() for c in hist.columns]
        if 'date' in hist.columns:
            # ğŸ’¡ å°è‚¡æ™‚é–“æ¸…ç†ï¼šè½‰ç‚ºç„¡æ™‚å€çš„ YYYY-MM-DD
            hist['date'] = pd.to_datetime(hist['date']).dt.tz_localize(None).dt.strftime('%Y-%m-%d')
        
        df_final = hist[['date', 'open', 'high', 'low', 'close', 'volume']].copy()
        df_final['symbol'] = symbol
        
        # 1. å­˜å…¥æœ¬æ©Ÿ CSV å¿«å–
        if not IS_GITHUB_ACTIONS:
            df_final.to_csv(csv_path, index=False)

        # 2. å­˜å…¥ SQL (é˜²é‡è¤‡)
        conn = sqlite3.connect(DB_PATH, timeout=30)
        df_final.to_sql('stock_prices', conn, if_exists='append', index=False, method=insert_or_replace)
        conn.close()
        
        return {"symbol": symbol, "status": "success"}
    except Exception:
        return {"symbol": symbol, "status": "error"}

# ========== 4. ä¸»æµç¨‹ ==========

def run_sync(mode='hot'):
    start_time = time.time()
    init_db()
    
    items = get_tw_stock_list()
    if not items:
        log("âŒ ç„¡æ³•å–å¾—å°è‚¡åå–®ï¼Œä»»å‹™çµ‚æ­¢ã€‚")
        return {"fail_list": [], "success": 0, "has_changed": False}

    log(f"ğŸš€ é–‹å§‹ä¸‹è¼‰ TW ({mode.upper()}) | ç›®æ¨™: {len(items)} æª”")

    stats = {"success": 0, "cache": 0, "empty": 0, "error": 0}
    fail_list = []
    task_args = [(it[0], it[1], mode) for it in items]
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(download_one, arg): arg for arg in task_args}
        pbar = tqdm(total=len(items), desc=f"TWè™•ç†ä¸­({mode})")
        
        for f in as_completed(futures):
            res = f.result()
            s = res.get("status", "error")
            stats[s] += 1
            if s == "error":
                fail_list.append(res.get("symbol"))
            pbar.update(1)
        pbar.close()

    # ğŸ’¡ åˆ¤æ–·è®Šå‹•æ¨™è¨˜
    has_changed = stats['success'] > 0
    
    if has_changed or IS_GITHUB_ACTIONS:
        log("ğŸ§¹ åµæ¸¬åˆ°è®Šå‹•æˆ–é›²ç«¯ç’°å¢ƒï¼Œå„ªåŒ–è³‡æ–™åº« (VACUUM)...")
        conn = sqlite3.connect(DB_PATH)
        conn.execute("VACUUM")
        conn.close()
    else:
        log("â© å°è‚¡æ•¸æ“šç„¡æ›´æ–°ï¼Œè·³é VACUUMã€‚")

    duration = (time.time() - start_time) / 60
    log(f"ğŸ“Š åŒæ­¥å®Œæˆï¼è²»æ™‚: {duration:.1f} åˆ†é˜")
    log(f"âœ… æ–°å¢: {stats['success']} | âš¡ å¿«å–è·³é: {stats['cache']} | âŒ éŒ¯èª¤: {stats['error']}")

    return {
        "success": stats['success'] + stats['cache'],
        "fail_list": fail_list,
        "has_changed": has_changed
    }

if __name__ == "__main__":
    run_sync(mode='hot')