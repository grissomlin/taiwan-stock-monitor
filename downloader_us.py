# -*- coding: utf-8 -*-
import os, time, random, requests, json
import pandas as pd
import yfinance as yf
from datetime import datetime
from io import StringIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from pathlib import Path

# ========== æ ¸å¿ƒåƒæ•¸è¨­å®š ==========
MARKET_CODE = "us-share"
DATA_SUBDIR = "dayK"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data", MARKET_CODE, DATA_SUBDIR)
LIST_DIR = os.path.join(BASE_DIR, "data", MARKET_CODE, "lists")
CACHE_LIST_PATH = os.path.join(LIST_DIR, "us_stock_list_cache.json")

# âœ… æ•ˆèƒ½å„ªåŒ–ï¼š5 å€‹åŸ·è¡Œç·’å°ç¾è‚¡è€Œè¨€æ˜¯è¼ƒç©©å®šçš„é¸æ“‡
MAX_WORKERS = 5 
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(LIST_DIR, exist_ok=True)

def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}")

def classify_security(name: str, is_etf: bool) -> str:
    if is_etf: return "Exclude"
    n_upper = str(name).upper()
    exclude_keywords = ["WARRANT", "RIGHTS", "UNIT", "PREFERRED", "DEPOSITARY", "ADR", "FOREIGN", "DEBENTURE"]
    if any(kw in n_upper for kw in exclude_keywords): return "Exclude"
    return "Common Stock"

def get_full_stock_list():
    """ç²å–ç¾è‚¡æ¸…å–®ï¼Œå¢åŠ  3000 æª”é˜²å‘†é–€æª»"""
    threshold = 3000
    
    # 1. æª¢æŸ¥ä»Šæ—¥å¿«å–
    if os.path.exists(CACHE_LIST_PATH):
        try:
            file_mtime = os.path.getmtime(CACHE_LIST_PATH)
            if datetime.fromtimestamp(file_mtime).date() == datetime.now().date():
                with open(CACHE_LIST_PATH, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if len(data) >= threshold:
                        log(f"ğŸ“¦ è¼‰å…¥ä»Šæ—¥ç¾è‚¡å¿«å– ({len(data)} æª”)...")
                        return data
        except: pass

    log("ğŸ“¡ é–‹å§‹å¾å®˜ç¶²ç²å–ç¾è‚¡æ™®é€šè‚¡æ¸…å–®...")
    all_rows = []

    for site in ["nasdaqlisted.txt", "otherlisted.txt"]:
        try:
            url = f"https://www.nasdaqtrader.com/dynamic/symdir/{site}"
            r = requests.get(url, timeout=15)
            df = pd.read_csv(StringIO(r.text), sep="|")
            df = df[df["Test Issue"] == "N"]
            
            sym_col = "Symbol" if site == "nasdaqlisted.txt" else "NASDAQ Symbol"
            df["Category"] = df.apply(lambda row: classify_security(row["Security Name"], row["ETF"] == "Y"), axis=1)
            valid_df = df[df["Category"] == "Common Stock"]
            
            for _, row in valid_df.iterrows():
                ticker = str(row[sym_col]).strip().replace('$', '-')
                name = str(row['Security Name']).strip()
                all_rows.append(f"{ticker}&{name}")
            time.sleep(1) 
        except Exception as e:
            log(f"âš ï¸ {site} ç²å–å¤±æ•—: {e}")

    final_list = list(set(all_rows))
    
    if len(final_list) >= threshold:
        with open(CACHE_LIST_PATH, "w", encoding="utf-8") as f:
            json.dump(final_list, f, ensure_ascii=False)
        log(f"âœ… ç¾è‚¡æ¸…å–®æ›´æ–°å®Œæˆï¼Œå…± {len(final_list)} æª”ã€‚")
        return final_list
    elif os.path.exists(CACHE_LIST_PATH):
        log("âš ï¸ ç²å–æ•¸é‡ä¸è¶³ï¼Œä½¿ç”¨æ­·å²å¿«å–å‚™æ´...")
        with open(CACHE_LIST_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    
    return final_list

def download_stock_data(item):
    """å–®æª”ä¸‹è¼‰ï¼šå…·å‚™éš¨æ©Ÿäº‚æ•¸èˆ‡é‡è©¦æ©Ÿåˆ¶"""
    yf_tkr = "Unknown"
    try:
        yf_tkr, name = item.split('&', 1)
        safe_name = "".join([c for c in name if c.isalnum() or c in (' ', '_', '-')]).strip()
        out_path = os.path.join(DATA_DIR, f"{yf_tkr}_{safe_name}.csv")
        
        if os.path.exists(out_path) and os.path.getsize(out_path) > 1000:
            return {"status": "exists", "tkr": yf_tkr}

        # ğŸš€ ä¸‹è¼‰å‰éš¨æ©Ÿç­‰å¾…ï¼Œåˆ†æ•£ GitHub Action å‡ºå£ IP å£“åŠ›
        time.sleep(random.uniform(0.4, 1.2))
        tk = yf.Ticker(yf_tkr)
        
        for attempt in range(2):
            try:
                hist = tk.history(period="2y", timeout=20)
                if hist is not None and not hist.empty:
                    hist.reset_index(inplace=True)
                    hist.columns = [c.lower() for c in hist.columns]
                    if 'date' in hist.columns:
                        hist['date'] = pd.to_datetime(hist['date'], utc=True).dt.tz_localize(None)
                    hist.to_csv(out_path, index=False, encoding='utf-8-sig')
                    return {"status": "success", "tkr": yf_tkr}
            except Exception as e:
                if "Rate limited" in str(e):
                    time.sleep(random.uniform(20, 40))
            
            time.sleep(random.uniform(2, 4))

        return {"status": "empty", "tkr": yf_tkr}
    except:
        return {"status": "error"}

def main():
    start_time = time.time()
    items = get_full_stock_list()
    if not items: 
        log("âŒ ç„¡æ³•å–å¾—æ¸…å–®ã€‚")
        return {"total": 0, "success": 0, "fail": 0}

    log(f"ğŸš€ é–‹å§‹ç¾è‚¡ä¸‹è¼‰ä»»å‹™ (å…± {len(items)} æª”)")
    stats = {"success": 0, "exists": 0, "empty": 0, "error": 0}
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(download_stock_data, it): it for it in items}
        pbar = tqdm(total=len(items), desc="ç¾è‚¡ä¸‹è¼‰é€²åº¦")
        for future in as_completed(futures):
            res = future.result()
            stats[res.get("status", "error")] += 1
            pbar.update(1)
        pbar.close()
    
    # --- ğŸ’¡ æ•¸æ“šä¸‹è¼‰çµ±è¨ˆ (ä¾› Email é€šçŸ¥ä½¿ç”¨) ---
    total_expected = len(items)
    effective_success = stats['success'] + stats['exists']
    fail_count = stats['error'] + stats['empty']

    download_stats = {
        "total": total_expected,
        "success": effective_success,
        "fail": fail_count
    }

    duration = (time.time() - start_time) / 60
    log("="*30)
    log(f"ğŸ ç¾è‚¡ä¸‹è¼‰ä»»å‹™å®Œæˆ (è€—æ™‚ {duration:.1f} åˆ†é˜)")
    log(f"   - ç¸½è¨ˆæ¨™çš„: {total_expected}")
    log(f"   - ä¸‹è¼‰æˆåŠŸ: {effective_success}")
    log(f"   - å¤±æ•—/ç¼ºå¤±: {fail_count}")
    log(f"ğŸ“ˆ æ•¸æ“šå®Œæ•´åº¦: {(effective_success/total_expected)*100:.2f}%")
    log("="*30)
    
    return download_stats # ğŸš€ å›å‚³çµ±è¨ˆå­—å…¸ä¾›ä¸»ç¨‹å¼ä½¿ç”¨

if __name__ == "__main__":
    main()
